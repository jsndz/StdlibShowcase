Abstract:
The idea is to build a developer dashboard that will track the stdlib ecosystem. Since the database already exist the goal is to implement a backend and frontend application that can show a real time interface. Since the database needs to less loaded we will go with static snapshots which will be stored in JSON format. Subsequent rollups will be applied.

![Image](https://github.com/user-attachments/assets/d545d568-7363-4885-911d-042575335dbf)

Basic Features:
- Backend for handling database query
- Frontend Dashboard interface
- Quick  Navigation 
- Filtering and pagination
- data analysis for historical overviews and drill down metrics

Implementation
1. Backend for Handling Database Queries
 Tech Stack
Fastify â†’ Optimized for performance and used in other stdlib projects.
PostgreSQL â†’ The existing database for storing repository and build data.
NodeJS Cron (node-cron) â†’ Used for generating static snapshots periodically.

<b style="font-weight:normal;" id="docs-internal-guid-6f9feb4d-7fff-ea8d-58da-89c9f960f703"><h2 dir="ltr" style="line-height:1.38;margin-top:18pt;margin-bottom:4pt;"><span style="font-size:16pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">These are the basic endpoints that will be provided by the server</span></h2><div dir="ltr" style="margin-left:0pt;" align="left">
Method | Endpoint | Description
-- | -- | --


</div></b>

Cron Job for Generating Snapshots

`// Function to generate static snapshot
async function generateSnapshot() {
  const snapshotData = [{ repository_id: 1, name: "repo1", status: "success" }];
  fs.writeFileSync("snapshot.json", JSON.stringify(snapshotData, null, 2));
  console.log("ðŸ“Œ Snapshot updated at", new Date().toISOString());
}

// Schedule cron job (Runs every midnight UTC)
cron.schedule("0 0 * * *", generateSnapshot);



fastify.get("/", async (request, reply) => {
  return { message: "Welcome to the Ecosystem Build Tracker API!" };
});

fastify.get("/api/dashboard", async (request, reply) => {
  return [];
});

fastify.get("/api/metrics", async (request, reply) => {
  return {};
});

fastify.get("/api/metrics/:id", async (request, reply) => {
  return {};
});

fastify.get("/api/snapshot", async (req, reply) => {
  const data = fs.readFileSync("snapshot.json", "utf-8");
  return JSON.parse(data);
});
`

Rollups will be done in the backend so that the frontend does not have do the aggregate
The important Rollups  that i can think of are:
Metrics for single repository and metrics for overall repositories

2. Frontend Dashboard Interface
Tech Stack:

- React because familiarity and simplicity 
- Tailwind CSS for styling
- ESBuild for bundling

Frontend will provide three views
Dashboard: Which consist of list of repositories and their information
Metrics: Overall metrics for all the repositories like overall build stats etc
Repository Metrics: Metrics for specific Repository. Showing all the information on builds 
Here is the figma wireframe:
https://www.figma.com/design/BAi2bJqo1vT2oZciUaGtW5/gsoc?node-id=0-1&t=jytcAuJezuGFBHb5-1
This is my first time using figma so there might be inconsistency

![Image](https://github.com/user-attachments/assets/9bcb8bb3-e83b-48b8-995a-74dc818928a6)


3. Quick Navigation
Navigation Approaches:
The three approaches that can be taken is to do is
Frontend Search 
The searching functionality will be fully done on the browser. Can use libraries like minisearch for this.

import MiniSearch from 'minisearch'

export function setupSearchIndex(data) {
  // Initialize and configure MiniSearch
  // Add data to the index
}

export function search(query) {
  // Run search against the index
}
async function init() {
  // Fetch snapshot or pre-indexed data
  // Call setupSearchIndex(data)
}

function handleSearchInput(event) {
  const query = event.target.value
  // Call search(query) and render results
}


Backend search
Backend search involves indexing the snapshot which is a better method considering the size of the database. This is done by creating a precomputed index file alongside the snapshot.

function generateIndexFromSnapshot(snapshot) {
  // Logic to create an index file from the snapshot
}

function saveIndexToFile(index, filePath) {
  // Logic to write the index to a file
}
function loadIndex(filePath) {
  // Logic to load the index from disk
}

function searchIndex(index, query) {
  // Logic to search the precomputed index
}
app.get('/search', (req, res) => {
  // Handle query and return results
});

Hybrid approach 
Hybrid approach uses both of these. And I am not very sure about it because this might be considered as an overkill.

The specific usage may need to be discussed with the mentor.
The approach I am suggesting will be indexing the database.


<b style="font-weight:normal;" id="docs-internal-guid-23f1a9cd-7fff-e19d-ae46-629ed2c7140a"><h3 dir="ltr" style="line-height:1.38;margin-top:14pt;margin-bottom:4pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">4. Filtering&nbsp;</span></h3><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:13pt;font-family:Arial,sans-serif;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><br /></li></ul><div dir="ltr" style="margin-left:0pt;" align="left">
Filter Category | Filter Option | Available Options | Purpose
-- | -- | -- | --
Status Filters | Build Status (Dropdown) | All, Success, Failure, In Progress, Canceled | Allows users to filter builds based on their current status.
Â  | Conclusion (Dropdown) | All, Passed, Failed, Canceled | Refines failure analysis by differentiating between different outcomes.
Repository & Owner Filters | Repository Name (Search/Dropdown) | User-entered text | Enables users to find builds related to a specific repository quickly.
Â  | Owner (Dropdown) | User-entered text | Helps filter builds by repository owner for better organization.
Time-Based Filters | Time Range (Dropdown) | Last 1 hour, Last 24 hours, Last 7 days, Custom date range | Allows users to filter builds within a specific timeframe.
Â  | Build Duration (Slider/Input Range) | Min - Max duration (e.g., 0 min - 60 min) | Filters builds based on duration to identify short or long-running builds.
Build & Workflow Filters | Workflow Name (Dropdown) | User-entered text | Helps users filter by specific CI/CD workflows executed in the build process.
Â  | Triggered By (Dropdown) | All, Push, Pull Request, Schedule | Allows filtering builds based on the event that triggered them.
Â  | Run Number / Attempt (Search Box) | User-entered number | Helps users locate a specific build run by its unique identifier.
Commit Filters (Optional) | Commit Author (Search Box) | User-entered text | Enables filtering builds based on the developer who authored the commit.
Â  | Commit Message Contains (Search Box) | User-entered text | Allows users to find builds related to specific changes by searching commit messages.
Â  | Branch Name (Dropdown) | User-entered text | Filters builds by branch to differentiate between Main, Develop, and Feature branches.

</div></b>


The filter implementation is given here:

![Image](https://github.com/user-attachments/assets/a84ed87a-259d-4752-aa3a-adba637937eb)


How filtering will be done:
For filtering we are going with doing the filtering in the backend.
Since the database is large and the size will increase the best approach would be filtering on the backend
The frontend will send filters with pagination setup. The backend will handle filtering and will send the required data.

Example API call:
GET /api/dashboard?page=1&limit=100&status=failed&owner=stdlib


5. Data Analysis for Historical Overviews and Drill-Down Metrics
Stages:
Data Querying & Aggregation
Querying data based on specific time intervals.
Based on the time interval we will filter data then we will get analytics for them
To get accurate data we need aggregate the data 
We can create rollups during the snapshot creation
Specific rollups needs to decided after talking to the mentors
The ones that i can think of are metrics for individual repo and a combined one for all repositories which will include things like failures to build graph etc
Visualization
Representing data in graphs and charts.
Some visualization metrics that researched are give here


Failure Rate of repositories  (Line Chart) uses repository_id, conclusion from workflow_run
Overall trend of build successes vs failures across all repos(Bar Chart) uses status, conclusion from workflow_run
NPM download trend (line chart) uses repository_id, count from	    npm_download_count
How long builds are taking on average (histogram) 
repository_id, created_at, updated_at from workflow_run 

Drill-Down Metrics:
Drill down metrics can be implemented for failure in the repository
Drill-down options are:
Specific repositories.
Branches.
Individual commits.
